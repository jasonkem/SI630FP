{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.data import Dataset, Subset\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizerFast, RobertaForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "import krippendorff\n",
    "from better_profanity import profanity\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa Token Classification Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:40: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16100 comments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 12880, Validation samples: 3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4830' max='4830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4830/4830 2:59:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.172281</td>\n",
       "      <td>0.926650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.192601</td>\n",
       "      <td>0.926534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.170995</td>\n",
       "      <td>0.926296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.168577</td>\n",
       "      <td>0.926375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.159800</td>\n",
       "      <td>0.170786</td>\n",
       "      <td>0.926679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.183538</td>\n",
       "      <td>0.926679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.153000</td>\n",
       "      <td>0.173084</td>\n",
       "      <td>0.926677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.168463</td>\n",
       "      <td>0.926677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.170222</td>\n",
       "      <td>0.926605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/450112072.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='403' max='403' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [403/403 01:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.17078591883182526, 'eval_accuracy': 0.9266790890269151, 'eval_runtime': 63.6994, 'eval_samples_per_second': 50.55, 'eval_steps_per_second': 6.327, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    \n",
    "    # Merge annotations and spans on the \"annotation\" column.\n",
    "    # This associates each toxic span (from spans_df) with its corresponding annotation from annotations_df.\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    \n",
    "    # For each comment, combine spans from all annotations.\n",
    "    # If a comment receives multiple annotations, we simply combine all toxic spans.\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(\n",
    "        lambda df: list(zip(df[\"start\"], df[\"end\"]))\n",
    "    ).to_dict()\n",
    "    \n",
    "    # For every comment, obtain the text and its corresponding list of toxic spans (empty if none found)\n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    \n",
    "    return texts, spans\n",
    "\n",
    "# Helper function: Tokenize text and align token-level labels using offset mappings.\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    # Since the encodings are dictionaries, I need to collate them into a dict of lists.\n",
    "    # I did  this by using the tokenizer's pad method on the list of encodings.\n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    # Convert labels_list to a tensor and pad them similarly.\n",
    "    # For simplicity, I pad labels manually to max_length.\n",
    "    padded_labels = [labels + [0]*(max_length - len(labels)) if len(labels) < max_length else labels[:max_length] for labels in labels_list]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    indices = list(range(len(texts)))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        return selected, selected_labels\n",
    "    \n",
    "    train_enc, train_labels = select_batch(batch_encoding, batch_labels, train_idx)\n",
    "    val_enc, val_labels = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "\n",
    "    train_dataset = ToxicSpanDataset(train_enc, train_labels.tolist())\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist())\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# Compute token-level accuracy metric (flatten over all tokens)\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    accuracy = (preds == labels).mean().item()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    model = RobertaForTokenClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "    \n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    print(f\"Loaded {len(texts)} comments.\")\n",
    "    \n",
    "    # Prepare datasets (train and validation)\n",
    "    train_dataset, val_dataset = prepare_datasets(texts, spans, tokenizer)\n",
    "    print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=100,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=500,\n",
    "        save_steps=500,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"accuracy\"\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation Results: {eval_results}\")\n",
    "    trainer.save_model(\"./final_model\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Model & Tokenizer Initialization**  \n",
    "  Loads the `roberta-base` tokenizer and model with a token-classification head for two labels (toxic vs. non‑toxic). This directly implements the choice of RoBERTa described in the Introduction.\n",
    "\n",
    "- **Data Loading & Merging**  \n",
    "  Reads `comments.csv`, `annotations.csv`, and `spans.csv`, then merges them to associate each comment with its character-level toxic spans. This mirrors the Data section’s explanation of reconstructing spans per comment.\n",
    "\n",
    "- **Tokenization & Label Alignment**  \n",
    "  Uses `return_offsets_mapping` to map each token back to character indices and assigns a binary label if a token overlaps any toxic span. This implements the span‑to‑token alignment process described for creating token‑level annotations.\n",
    "\n",
    "- **Preparing Train/Validation Splits**  \n",
    "  Pads all tokenized examples to a fixed length, then performs an 80–20 split into training and validation sets. This reproduces the dataset division reported (12,880 train vs. 3,220 validation samples).\n",
    "\n",
    "- **Custom Dataset Class**  \n",
    "  Defines `ToxicSpanDataset` to wrap encodings and labels into a PyTorch `Dataset`, converting values to tensors on the fly. This supports feeding data into Hugging Face’s `Trainer` exactly as outlined in the Methods.\n",
    "\n",
    "- **Training Configuration**  \n",
    "  Specifies three epochs, batch size of 8, warmup steps, weight decay, and step-wise evaluation with accuracy as the key metric. These hyperparameters align with those tuned during the experimental setup.\n",
    "\n",
    "- **Metric Computation**  \n",
    "  Flattens both predictions and true labels across all tokens and computes simple accuracy. This replicates the token-level accuracy metric used throughout the Evaluation section.\n",
    "\n",
    "- **Training, Evaluation & Saving**  \n",
    "  Instantiates a `Trainer` with the model, datasets, and metrics; runs fine-tuning; evaluates on the validation set; and saves the best model. This end‑to‑end pipeline corresponds to the core experiments whose results were discuss in Sections 5–7.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RoBERTa Model Evaluation Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/332077579.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16100 comments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/332077579.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='403' max='403' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [403/403 01:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.17078591883182526, 'eval_model_preparation_time': 0.0023, 'eval_accuracy': 0.9266790890269151, 'eval_f1': 0.9298788121032561, 'eval_runtime': 65.6089, 'eval_samples_per_second': 49.079, 'eval_steps_per_second': 6.142}\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    \n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(\n",
    "        lambda df: list(zip(df[\"start\"], df[\"end\"]))\n",
    "    ).to_dict()\n",
    "    \n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    \n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0] * (max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    indices = list(range(len(texts)))\n",
    "    _, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        return selected, selected_labels\n",
    "    \n",
    "    val_enc, val_labels = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist())\n",
    "    return val_dataset\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    accuracy = (preds == labels).mean().item()\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "def main():\n",
    "\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    model = RobertaForTokenClassification.from_pretrained(\"./final_model\", num_labels=2)\n",
    "    \n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    print(f\"Loaded {len(texts)} comments.\")\n",
    "    \n",
    "    val_dataset = prepare_datasets(texts, spans, tokenizer, max_length=150)\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        per_device_eval_batch_size=8,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation Results: {eval_results}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Loading the Fine‑Tuned Model**  \n",
    "  Initializes the `roberta-base` tokenizer and loads the saved checkpoint from `./final_model`, mirroring Section 5’s evaluation of the final model rather than re‑training from scratch.\n",
    "\n",
    "- **Data Preprocessing & Validation Split**  \n",
    "  Reads and merges `comments.csv`, `annotations.csv`, and `spans.csv` just as before, but now only constructs the 20% hold‑out validation set (≈3,220 examples). This aligns with the reported validation sample size and focuses solely on evaluation.\n",
    "\n",
    "- **Tokenization & Label Alignment for Validation**  \n",
    "  Uses `tokenize_and_align_labels` and `tokenizer.pad` to convert each comment into token IDs and binary labels up to a fixed length (150 tokens). This replicates the token‑level annotation process detailed in Section 2.\n",
    "\n",
    "- **Extended Metric Computation**  \n",
    "  Flattens predictions and true labels to compute both simple accuracy and a weighted F1 score via `f1_score(labels, preds, average=\"weighted\")`. These metrics correspond directly to the 92.7% accuracy and 93% F1 reported in the Results section.\n",
    "\n",
    "- **Evaluation-Only Trainer**  \n",
    "  Constructs a `Trainer` with only evaluation arguments (`per_device_eval_batch_size=8`) and calls `trainer.evaluate()` to produce the final performance metrics. This execution reproduces the exact evaluation pipeline described in Section 5.3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Error Analysis and Misclassified Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/3593021654.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16100 comments.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/3593021654.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.17078591883182526, 'eval_model_preparation_time': 0.0028, 'eval_accuracy': 0.9266790890269151, 'eval_f1': 0.9298788121032561, 'eval_runtime': 64.1176, 'eval_samples_per_second': 50.22, 'eval_steps_per_second': 6.285}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/3593021654.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[336323  35414]\n",
      " [     0 111263]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95    371737\n",
      "           1       0.76      1.00      0.86    111263\n",
      "\n",
      "    accuracy                           0.93    483000\n",
      "   macro avg       0.88      0.95      0.91    483000\n",
      "weighted avg       0.94      0.93      0.93    483000\n",
      "\n",
      "Misclassified examples:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/3593021654.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3:\n",
      "Tokens: ['<s>', 'A', 'Ġclimate', 'Ġchange', 'Ġstudy', 'Ġwas', 'Ġconducted', 'Ġby', 'ĠMIT', 'Ġin', 'ĠApril', 'Ġ2016', ',', 'Ġtitled', \"Ġ'\", 'How', 'Ġmuch', 'Ġof', 'Ġa', 'Ġdifference', 'Ġwill', 'Ġthe', 'ĠParis', 'ĠAgreement', 'Ġmake', '?', \"'.\", 'Ġ\"', 'The', 'Ġresearch', 'Ġshowed', 'Ġthat', 'Ġif', 'Ġcountries', 'Ġab', 'ided', 'Ġby', 'Ġtheir', 'Ġpledges', 'Ġin', 'Ġthe', 'Ġdeal', ',', 'Ġglobal', 'Ġwarming', 'Ġwould', 'Ġslow', 'Ġby', 'Ġbetween', 'Ġ0', '.', '6', 'Ġdegree', 'Ġand', 'Ġ1', '.', '1', 'Ġdegrees', 'ĠCelsius', 'Ġby', 'Ġ2100', ',', 'ĠReuters', 'Ġreported', '.\"', 'Ċ', 'Ċ', 'Wow', '!', 'ĠA', 'Ġ1', '%', 'Ġslowing', 'Ġdown', 'Ġof', 'Ġglobal', 'Ġwarming', 'Ġafter', 'Ġ80', 'Ġyears', '!', 'Ġ', 'ĠIn', 'Ġother', 'Ġwords', ',', 'Ġit', 'Ġwould', 'Ġmake', 'Ġa', 'Ġtiny', 'Ġdifference', '.', 'Ġ', 'ĠTHAT', \"'\", 'S', 'Ġ\"', 'IF', 'ĠCOUN', 'TR', 'IES', 'ĠAB', 'ID', 'ED', 'ĠBY', 'ĠTHEIR', 'ĠPL', 'ED', 'GES', 'ĠIN', 'ĠTHE', 'ĠDE', 'AL', '!\"', 'Ġ', 'ĠA', 'Ġnon', '-', 'binding', 'Ġagreement', 'Ġthat', 'Ġhas', 'Ġno', 'Ġteeth', '.', 'Ġ', 'ĠLet', \"'s\", 'Ġsee', ',', 'ĠI', 'Ġwonder', 'Ġhow', 'Ġmany', 'Ġcountries', 'Ġwould', 'Ġkeep', 'Ġtheir', 'Ġpromises', 'Ġwhen', 'Ġnothing', 'Ġwould', 'Ġhappen', 'Ġif', 'Ġthey', 'Ġdidn', \"'t\", '.', '</s>']\n",
      "Misclassifications (token, prediction, true): [('A', 1, 0), ('Ġclimate', 1, 0), ('Ġchange', 1, 0), ('Ġstudy', 1, 0), ('Ġwas', 1, 0), ('Ġconducted', 1, 0), ('Ġby', 1, 0), ('ĠMIT', 1, 0), ('Ġin', 1, 0), ('ĠApril', 1, 0), ('Ġ2016', 1, 0), (',', 1, 0), ('Ġtitled', 1, 0), (\"Ġ'\", 1, 0), ('How', 1, 0), ('Ġmuch', 1, 0), ('Ġof', 1, 0), ('Ġa', 1, 0), ('Ġdifference', 1, 0), ('Ġwill', 1, 0), ('Ġthe', 1, 0), ('ĠParis', 1, 0), ('ĠAgreement', 1, 0), ('Ġmake', 1, 0), ('?', 1, 0), (\"'.\", 1, 0), ('Ġ\"', 1, 0), ('The', 1, 0), ('Ġresearch', 1, 0), ('Ġshowed', 1, 0), ('Ġthat', 1, 0), ('Ġif', 1, 0), ('Ġcountries', 1, 0), ('Ġab', 1, 0), ('ided', 1, 0), ('Ġby', 1, 0), ('Ġtheir', 1, 0), ('Ġpledges', 1, 0), ('Ġin', 1, 0), ('Ġthe', 1, 0), ('Ġdeal', 1, 0), (',', 1, 0), ('Ġglobal', 1, 0), ('Ġwarming', 1, 0), ('Ġwould', 1, 0), ('Ġby', 1, 0), ('Ġbetween', 1, 0), ('Ġ0', 1, 0), ('.', 1, 0), ('6', 1, 0), ('Ġdegree', 1, 0), ('Ġand', 1, 0), ('Ġ1', 1, 0), ('.', 1, 0), ('1', 1, 0), ('Ġdegrees', 1, 0), ('ĠCelsius', 1, 0), ('Ġby', 1, 0), ('Ġ2100', 1, 0), (',', 1, 0), ('ĠReuters', 1, 0), ('Ġreported', 1, 0), ('.\"', 1, 0), ('Ċ', 1, 0), ('Ċ', 1, 0), ('Wow', 1, 0), ('!', 1, 0), ('ĠA', 1, 0), ('Ġ1', 1, 0), ('%', 1, 0), ('Ġslowing', 1, 0), ('Ġdown', 1, 0), ('Ġof', 1, 0), ('Ġglobal', 1, 0), ('Ġwarming', 1, 0), ('Ġafter', 1, 0), ('Ġ80', 1, 0), ('Ġyears', 1, 0), ('!', 1, 0), ('Ġ', 1, 0), ('ĠIn', 1, 0), ('Ġother', 1, 0), ('Ġwords', 1, 0), (',', 1, 0), ('Ġit', 1, 0), ('Ġwould', 1, 0), ('Ġmake', 1, 0), ('Ġa', 1, 0), ('Ġtiny', 1, 0), ('Ġdifference', 1, 0), ('.', 1, 0), ('Ġ', 1, 0), ('ĠTHAT', 1, 0), (\"'\", 1, 0), ('S', 1, 0), ('Ġ\"', 1, 0), ('IF', 1, 0), ('ĠCOUN', 1, 0), ('TR', 1, 0), ('IES', 1, 0), ('ĠAB', 1, 0), ('ID', 1, 0), ('ED', 1, 0), ('ĠBY', 1, 0), ('ĠTHEIR', 1, 0), ('ĠPL', 1, 0), ('ED', 1, 0), ('GES', 1, 0), ('ĠIN', 1, 0), ('ĠTHE', 1, 0), ('ĠDE', 1, 0), ('AL', 1, 0), ('!\"', 1, 0), ('Ġ', 1, 0), ('ĠA', 1, 0), ('Ġnon', 1, 0), ('-', 1, 0), ('binding', 1, 0), ('Ġagreement', 1, 0), ('Ġthat', 1, 0), ('Ġhas', 1, 0), ('Ġno', 1, 0), ('Ġteeth', 1, 0), ('.', 1, 0), ('Ġ', 1, 0), ('ĠLet', 1, 0), (\"'s\", 1, 0), ('Ġsee', 1, 0), (',', 1, 0), ('ĠI', 1, 0), ('Ġwonder', 1, 0), ('Ġhow', 1, 0), ('Ġmany', 1, 0), ('Ġcountries', 1, 0), ('Ġwould', 1, 0), ('Ġif', 1, 0), ('Ġthey', 1, 0), ('Ġdidn', 1, 0), (\"'t\", 1, 0), ('.', 1, 0)]\n",
      "\n",
      "Example 5:\n",
      "Tokens: ['<s>', 'He', 'Ġis', 'Ġa', 'Ġbitter', 'Ġfool', 'Ġand', 'Ġ', 'Ġknows', 'Ġhe', 'Ġhas', 'Ġnot', 'Ġtoo', 'Ġmuch', 'Ġtime', 'Ġto', 'Ġbe', 'Ġaround', 'Ġso', ',', 'Ġhe', 'Ġwants', 'Ġto', 'Ġgo', 'Ġas', 'Ġan', 'ĠAmerican', 'Ġhero', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Misclassifications (token, prediction, true): [('He', 1, 0), ('Ġis', 1, 0), ('Ġa', 1, 0), ('Ġand', 1, 0), ('Ġ', 1, 0), ('Ġknows', 1, 0), ('Ġhe', 1, 0), ('Ġhas', 1, 0), ('Ġnot', 1, 0), ('Ġtoo', 1, 0), ('Ġmuch', 1, 0), ('Ġtime', 1, 0), ('Ġto', 1, 0), ('Ġbe', 1, 0), ('Ġaround', 1, 0), ('Ġso', 1, 0), (',', 1, 0), ('Ġhe', 1, 0), ('Ġwants', 1, 0), ('Ġto', 1, 0), ('Ġgo', 1, 0), ('Ġas', 1, 0), ('Ġan', 1, 0), ('ĠAmerican', 1, 0), ('Ġhero', 1, 0), ('.', 1, 0)]\n",
      "\n",
      "Example 7:\n",
      "Tokens: ['<s>', 'You', 'Ġcan', \"'t\", 'Ġfix', 'Ġstupid', 'Ġand', 'ĠI', \"'m\", 'Ġnot', 'Ġtalking', 'Ġabout', 'ĠMs', 'ĠMoore', 'Ġor', 'ĠMs', '.', 'ĠMeier', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Misclassifications (token, prediction, true): [('You', 1, 0), ('Ġcan', 1, 0), (\"'t\", 1, 0), ('Ġfix', 1, 0), ('Ġand', 1, 0), ('ĠI', 1, 0), (\"'m\", 1, 0), ('Ġnot', 1, 0), ('Ġtalking', 1, 0), ('Ġabout', 1, 0), ('ĠMs', 1, 0), ('ĠMoore', 1, 0), ('Ġor', 1, 0), ('ĠMs', 1, 0), ('.', 1, 0), ('ĠMeier', 1, 0), ('.', 1, 0)]\n",
      "\n",
      "Example 10:\n",
      "Tokens: ['<s>', 'Do', 'Ġwhite', 'Ġpeople', 'Ġmarch', 'Ġin', 'Ġthe', 'Ġstreets', 'Ġwhen', 'Ġviolent', 'Ġwhite', 'Ġoffenders', 'Ġare', 'Ġkilled', 'Ġby', 'Ġthe', 'Ġpolice', '?', 'Ġ', 'ĠCalling', 'Ġfor', 'Ġthe', 'Ġdeath', 'Ġof', 'Ġpolice', 'Ġofficers', 'Ġbecause', 'Ġviolent', 'Ġblack', 'Ġoffenders', 'Ġresist', 'Ġarrest', 'Ġviolently', 'Ġand', 'Ġare', 'Ġshot', 'Ġbecause', 'Ġof', 'Ġit', '?', 'Ġ', 'ĠDis', 'g', 'usting', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Misclassifications (token, prediction, true): [('Ġpeople', 1, 0), ('Ġmarch', 1, 0), ('Ġin', 1, 0), ('Ġthe', 1, 0), ('Ġstreets', 1, 0), ('Ġwhen', 1, 0), ('Ġviolent', 1, 0), ('Ġwhite', 1, 0), ('Ġoffenders', 1, 0), ('Ġare', 1, 0), ('Ġkilled', 1, 0), ('Ġby', 1, 0), ('Ġthe', 1, 0), ('Ġpolice', 1, 0), ('?', 1, 0), ('Ġ', 1, 0), ('ĠCalling', 1, 0), ('Ġfor', 1, 0), ('Ġthe', 1, 0), ('Ġdeath', 1, 0), ('Ġof', 1, 0), ('Ġpolice', 1, 0), ('Ġofficers', 1, 0), ('Ġbecause', 1, 0), ('Ġviolent', 1, 0), ('Ġblack', 1, 0), ('Ġoffenders', 1, 0), ('Ġresist', 1, 0), ('Ġarrest', 1, 0), ('Ġviolently', 1, 0), ('Ġand', 1, 0), ('Ġare', 1, 0), ('Ġshot', 1, 0), ('Ġbecause', 1, 0), ('Ġof', 1, 0), ('Ġit', 1, 0), ('?', 1, 0), ('Ġ', 1, 0), ('.', 1, 0)]\n",
      "\n",
      "Example 11:\n",
      "Tokens: ['<s>', 'Trump', 'Ġis', 'Ġa', 'Ġtraitor', 'ous', 'Ġbuff', 'oon', '.', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "Misclassifications (token, prediction, true): [('Trump', 1, 0), ('Ġis', 1, 0), ('Ġa', 1, 0), ('.', 1, 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_misclassified_examples(trainer, dataset, tokenizer, n=5):\n",
    "    print(\"Misclassified examples:\")\n",
    "    device = trainer.model.device\n",
    "    count = 0\n",
    "    for i in range(len(dataset)):\n",
    "        sample = dataset[i]\n",
    "        # Move input tensors to the same device as the model\n",
    "        input_ids = sample[\"input_ids\"].unsqueeze(0).to(device)\n",
    "        true_labels = sample[\"labels\"].unsqueeze(0).to(device)\n",
    "        attention_mask = (input_ids != tokenizer.pad_token_id).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = trainer.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        preds = torch.argmax(outputs.logits, dim=-1).squeeze(0).cpu().numpy()\n",
    "        true_labels = true_labels.squeeze(0).cpu().numpy()\n",
    "        tokens = tokenizer.convert_ids_to_tokens(input_ids.squeeze(0).cpu().numpy())\n",
    "        \n",
    "        # This identifies misclassified tokens (ignoring pad tokens)\n",
    "        misclassified = [(t, int(pred), int(true)) for t, pred, true in zip(tokens, preds, true_labels)\n",
    "                         if t != tokenizer.pad_token and pred != true]\n",
    "        if misclassified:\n",
    "            print(f\"Example {i}:\")\n",
    "            print(\"Tokens:\", tokens)\n",
    "            print(\"Misclassifications (token, prediction, true):\", misclassified)\n",
    "            print(\"\")\n",
    "            count += 1\n",
    "            if count >= n:\n",
    "                break\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    model = RobertaForTokenClassification.from_pretrained(\"./final_model\", num_labels=2)\n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    print(f\"Loaded {len(texts)} comments.\")\n",
    "    \n",
    "    val_dataset = prepare_datasets(texts, spans, tokenizer, max_length=150)\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        per_device_eval_batch_size=8,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    eval_results = trainer.evaluate()\n",
    "    print(\"Evaluation Results:\", eval_results)\n",
    "    \n",
    "    preds_output = trainer.predict(val_dataset)\n",
    "    preds = np.argmax(preds_output.predictions, axis=-1).flatten()\n",
    "    true_labels = preds_output.label_ids.flatten()\n",
    "    \n",
    "    cm = confusion_matrix(true_labels, preds)\n",
    "    cr = classification_report(true_labels, preds)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Classification Report:\")\n",
    "    print(cr)\n",
    "    \n",
    "    display_misclassified_examples(trainer, val_dataset, tokenizer, n=5)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Quantitative Error Analysis**  \n",
    "  Uses `trainer.predict`, `confusion_matrix`, and `classification_report` to reproduce the detailed token‑level metrics (precision, recall, F1, confusion matrix) reported in Section 5.3, validating the model’s over‑prediction bias.\n",
    "\n",
    "- **Qualitative Error Inspection**  \n",
    "  The `display_misclassified_examples` function surfaces individual token misclassifications—exactly the “toxicity halos” and context‑dependent errors thats analyzed in Section 5.4 and discuss further in Section 6.\n",
    "\n",
    "- **End‑to‑End Evaluation Pipeline**  \n",
    "  By loading the fine‑tuned model, running batch predictions on the validation set, and combining both quantitative and qualitative outputs, this script operationalizes the full evaluation methodology described in the paper.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token Label Distribution Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/3885968139.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/3885968139.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens - Non-toxic (0): 1483743\n",
      "Training tokens - Toxic (1): 448257\n",
      "Total tokens: 1932000\n",
      "Proportion of toxic tokens: 0.2320170807453416\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "class ToxicSpanDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    # Loop through each token's offset to assign labels\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_train_dataset(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    # Pad the encodings\n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0] * (max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    indices = list(range(len(texts)))\n",
    "    train_idx, _ = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        return selected, selected_labels\n",
    "    train_enc, train_labels = select_batch(batch_encoding, batch_labels, train_idx)\n",
    "    train_dataset = ToxicSpanDataset(train_enc, train_labels.tolist())\n",
    "    return train_dataset\n",
    "\n",
    "def count_token_labels(dataset):\n",
    "    total_zeros = 0\n",
    "    total_ones = 0\n",
    "    for i in range(len(dataset)):\n",
    "        labels = np.array(dataset[i]['labels'])\n",
    "        total_zeros += np.sum(labels == 0)\n",
    "        total_ones += np.sum(labels == 1)\n",
    "    return total_zeros, total_ones\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    train_dataset = prepare_train_dataset(texts, spans, tokenizer, max_length=150)\n",
    "    train_zeros, train_ones = count_token_labels(train_dataset)\n",
    "    total_tokens = train_zeros + train_ones\n",
    "    print(\"Training tokens - Non-toxic (0):\", train_zeros)\n",
    "    print(\"Training tokens - Toxic (1):\", train_ones)\n",
    "    print(\"Total tokens:\", total_tokens)\n",
    "    print(\"Proportion of toxic tokens:\", train_ones / total_tokens)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Safe Tensor Conversion in `ToxicSpanDataset`**  \n",
    "  Clones and detaches tensors when indexing to ensure that returned items are independent of the original computation graph. This safeguards against in-place modifications during training or evaluation.\n",
    "\n",
    "- **Data Loading & Span Aggregation**  \n",
    "  Reads three CSV files—comments, annotations, and spans—and merges them on the `annotation` column to reconstruct all toxic spans for each comment. Outputs two lists: raw text strings and corresponding span tuples.\n",
    "\n",
    "- **Tokenization & Label Alignment**  \n",
    "  Uses the tokenizer’s offset mappings to assign a binary label to each token based on overlap with any span. Special tokens are skipped by checking for zero-length offsets before label assignment.\n",
    "\n",
    "- **Training Dataset Preparation**  \n",
    "  Tokenizes and pads all examples to a fixed length, converts labels into a matching tensor, and selects the 80% training subset via a reproducible split. Wraps the result in `ToxicSpanDataset` for seamless batching.\n",
    "\n",
    "- **Label Distribution Counting**  \n",
    "  Iterates through the entire training dataset to tally non‑toxic (0) and toxic (1) token counts. Calculates the overall proportion of toxic labels to quantify class imbalance.\n",
    "\n",
    "- **Execution & Reporting in `main`**  \n",
    "  Initializes the tokenizer, prepares the training dataset, counts token labels, and prints summary statistics—including total tokens and toxic token proportion—for quick dataset diagnostics.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter‑Annotator Agreement Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate (comment_id, worker) entries: 1\n",
      "Krippendorff's alpha: 0.5215211927440822\n"
     ]
    }
   ],
   "source": [
    "# Load the annotations CSV\n",
    "annotations_df = pd.read_csv(\"data/annotations.csv\")\n",
    "\n",
    "duplicates = annotations_df.duplicated(subset=[\"comment_id\", \"worker\"])\n",
    "print(\"Number of duplicate (comment_id, worker) entries:\", duplicates.sum())\n",
    "\n",
    "pivot_df = annotations_df.pivot_table(\n",
    "    index=\"comment_id\",\n",
    "    columns=\"worker\",\n",
    "    values=\"all toxic\",\n",
    "    aggfunc=lambda x: x.iloc[0]  # taking the first value if duplicates occur\n",
    ")\n",
    "\n",
    "pivot_df = pivot_df.replace({\"True\": 1, \"False\": 0})\n",
    "pivot_df = pivot_df.astype(float)\n",
    "\n",
    "data = pivot_df.to_numpy()\n",
    "\n",
    "# Compute Krippendorff's alpha using nominal measurement\n",
    "alpha = krippendorff.alpha(reliability_data=data, level_of_measurement='nominal')\n",
    "print(\"Krippendorff's alpha:\", alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loads and cleans the annotations CSV, checking for duplicate `(comment_id, worker)` pairs and resolving them by taking the first entry.  \n",
    "- Pivots the data into a matrix where each row is a comment and each column a worker’s binary “all toxic” label, then converts string values to numeric.  \n",
    "- Computes Krippendorff’s alpha on this nominal reliability matrix, matching the inter‑annotator agreement analysis (α ≈ 0.52) reported in the paper’s Evaluation section.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krippendorff's alpha of about 0.52 indicates moderate to low agreement among annotators on what they consider toxic spans. In many applications, values above 0.80 are considered good, while values below 0.67 suggest there may be considerable disagreement. This moderate agreement implies that the task of labeling toxic spans is challenging or that the annotation guidelines may need refinement. For this project, this insight can help explain models performances—if the ground truth is inconsistent, it may be harder for the model to learn a clear signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Prediction and Evaluation Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1236727181.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 3220\n",
      "\n",
      "Evaluating Baseline Rule-Based Approach:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1236727181.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Confusion Matrix:\n",
      "[[371723     14]\n",
      " [110343    920]]\n",
      "\n",
      "Baseline Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87    371737\n",
      "           1       0.99      0.01      0.02    111263\n",
      "\n",
      "    accuracy                           0.77    483000\n",
      "   macro avg       0.88      0.50      0.44    483000\n",
      "weighted avg       0.82      0.77      0.67    483000\n",
      "\n",
      "\n",
      "Baseline Weighted F1 Score: 0.6739407570877253\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "###########################################\n",
    "# DATA LOADING AND PREPROCESSING FUNCTIONS\n",
    "###########################################\n",
    "\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, texts=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        if self.texts is not None:\n",
    "            item['text'] = self.texts[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    \n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    \n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(\n",
    "        lambda df: list(zip(df[\"start\"], df[\"end\"]))\n",
    "    ).to_dict()\n",
    "    \n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0]*(max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    indices = list(range(len(texts)))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        selected_texts = [texts[i] for i in indices]\n",
    "        return selected, selected_labels, selected_texts\n",
    "    \n",
    "    train_enc, train_labels, train_texts = select_batch(batch_encoding, batch_labels, train_idx)\n",
    "    val_enc, val_labels, val_texts = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    \n",
    "    train_dataset = ToxicSpanDataset(train_enc, train_labels.tolist(), texts=train_texts)\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist(), texts=val_texts)\n",
    "    return train_dataset, val_dataset, val_texts\n",
    "\n",
    "###########################################\n",
    "# BASELINE RULE-BASED APPROACH\n",
    "###########################################\n",
    "\n",
    "# This is the set of toxic keywords for the baseline\n",
    "TOXIC_KEYWORDS = {\"idiot\", \"bitch\", \"moron\", \"fool\", \"stupid\", \"traitor\", \"fuck\", 'fucker', 'ass', 'dick'}\n",
    "\n",
    "def baseline_predict(text, tokenizer, max_length=150, toxic_keywords=TOXIC_KEYWORDS):\n",
    "    # Tokenize text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=False\n",
    "    )\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
    "    pred_labels = []\n",
    "    for token in tokens:\n",
    "        token_clean = token.lstrip(\"Ġ\").lower()\n",
    "        if token_clean in toxic_keywords:\n",
    "            pred_labels.append(1)\n",
    "        else:\n",
    "            pred_labels.append(0)\n",
    "    return pred_labels\n",
    "\n",
    "###########################################\n",
    "# EVALUATION FUNCTIONS\n",
    "###########################################\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    accuracy = (preds == labels).mean().item()\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "\n",
    "def evaluate_baseline(val_texts, val_dataset, tokenizer):\n",
    "    all_baseline = []\n",
    "    all_true = []\n",
    "    for i, text in enumerate(val_texts):\n",
    "        baseline_preds = baseline_predict(text, tokenizer, max_length=150)\n",
    "        true_labels = val_dataset[i]['labels'].cpu().numpy().tolist()\n",
    "        all_baseline.extend(baseline_preds)\n",
    "        all_true.extend(true_labels)\n",
    "    \n",
    "    cm = confusion_matrix(all_true, all_baseline)\n",
    "    cr = classification_report(all_true, all_baseline)\n",
    "    f1 = f1_score(all_true, all_baseline, average=\"weighted\")\n",
    "    print(\"Baseline Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nBaseline Classification Report:\")\n",
    "    print(cr)\n",
    "    print(\"\\nBaseline Weighted F1 Score:\", f1)\n",
    "\n",
    "###########################################\n",
    "# MAIN\n",
    "###########################################\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    _, val_dataset, val_texts = prepare_datasets(texts, spans, tokenizer, max_length=150)\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    print(\"\\nEvaluating Baseline Rule-Based Approach:\")\n",
    "    evaluate_baseline(val_texts, val_dataset, tokenizer)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data Loading & Preprocessing**  \n",
    "  Reads and merges `comments.csv`, `annotations.csv`, and `spans.csv` to reconstruct character‑level toxic spans per comment, then tokenizes and aligns labels exactly as described in the Data section.\n",
    "\n",
    "- **Custom Dataset Class**  \n",
    "  Wraps tokenized encodings, labels, and optional raw text into a PyTorch `Dataset`, supporting both neural and baseline evaluations without embedding model‑specific logic—consistent with the paper’s modular design.\n",
    "\n",
    "- **Rule‑Based Baseline**  \n",
    "  Implements the keyword‑matching approach from Section 4.1.1 via `TOXIC_KEYWORDS` and `baseline_predict`, tagging tokens whose cleaned form matches any predefined toxic word.\n",
    "\n",
    "- **Baseline Evaluation**  \n",
    "  Aggregates token‑level predictions and ground truth to produce a confusion matrix and weighted F1 score, replicating the baseline performance analysis (accuracy ≈77%, F1 ≈0.67) reported in Section 5.1.1.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-Based Profanity Detection Baseline (better_profanity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1604921198.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 3220\n",
      "\n",
      "Evaluating ML Baseline using better_profanity:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1604921198.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Baseline Confusion Matrix:\n",
      "[[371649     88]\n",
      " [109807   1456]]\n",
      "\n",
      "ML Baseline Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87    371737\n",
      "           1       0.94      0.01      0.03    111263\n",
      "\n",
      "    accuracy                           0.77    483000\n",
      "   macro avg       0.86      0.51      0.45    483000\n",
      "weighted avg       0.81      0.77      0.68    483000\n",
      "\n",
      "\n",
      "ML Baseline Weighted F1 Score: 0.676455046302137\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "###########################################\n",
    "# DATA LOADING AND PREPROCESSING FUNCTIONS\n",
    "###########################################\n",
    "\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, texts=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        if self.texts is not None:\n",
    "            item['text'] = self.texts[idx]\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    \n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    \n",
    "    # For each comment, combine spans from all annotations.\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
    "    \n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0]*(max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    indices = list(range(len(texts)))\n",
    "    _, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        selected_texts = [texts[i] for i in indices]\n",
    "        return selected, selected_labels, selected_texts\n",
    "    \n",
    "    val_enc, val_labels, val_texts = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist(), texts=val_texts)\n",
    "    return val_dataset, val_texts\n",
    "\n",
    "###########################################\n",
    "# ML-BASED BASELINE: BETTER PROFANITY\n",
    "###########################################\n",
    "\n",
    "def ml_baseline_predict(text, tokenizer, max_length=150):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=False\n",
    "    )\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
    "    pred_labels = []\n",
    "    for token in tokens:\n",
    "        token_clean = token.lstrip(\"Ġ\").lower()\n",
    "        if len(token_clean) < 2:\n",
    "            pred_labels.append(0)\n",
    "        else:\n",
    "            # Use better_profanity to check if token is profane\n",
    "            is_profane = profanity.contains_profanity(token_clean)\n",
    "            pred_labels.append(1 if is_profane else 0)\n",
    "    return pred_labels\n",
    "\n",
    "def evaluate_ml_baseline(val_texts, val_dataset, tokenizer):\n",
    "    all_baseline = []\n",
    "    all_true = []\n",
    "    for i, text in enumerate(val_texts):\n",
    "        baseline_preds = ml_baseline_predict(text, tokenizer, max_length=150)\n",
    "        true_labels = val_dataset[i]['labels'].cpu().numpy().tolist()\n",
    "        all_baseline.extend(baseline_preds)\n",
    "        all_true.extend(true_labels)\n",
    "    \n",
    "    cm = confusion_matrix(all_true, all_baseline)\n",
    "    cr = classification_report(all_true, all_baseline)\n",
    "    f1 = f1_score(all_true, all_baseline, average=\"weighted\")\n",
    "    \n",
    "    print(\"ML Baseline Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nML Baseline Classification Report:\")\n",
    "    print(cr)\n",
    "    print(\"\\nML Baseline Weighted F1 Score:\", f1)\n",
    "\n",
    "###########################################\n",
    "# MAIN\n",
    "###########################################\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    val_dataset, val_texts = prepare_datasets(texts, spans, tokenizer, max_length=150)\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    print(\"\\nEvaluating ML Baseline using better_profanity:\")\n",
    "    evaluate_ml_baseline(val_texts, val_dataset, tokenizer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implements the ML‑based baseline from Section 4.1.2 by tokenizing each comment and using `better_profanity` to label tokens as toxic or non‑toxic, matching the library‑driven approach in the paper.  \n",
    "- Aggregates baseline predictions and ground‑truth labels across the validation set to produce a confusion matrix, classification report, and weighted F1 score, replicating the evaluation described in Section 5.1.2.  \n",
    "- The `main` function initializes the tokenizer, prepares the validation dataset via the same preprocessing pipeline used for RoBERTa, and runs the baseline evaluation to compare performance against rule‑based and transformer‑based methods.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparative Evaluation and Visualization of RoBERTa vs. Baseline Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/2292988907.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/2292988907.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoBERTa Model - Accuracy: 0.93, Weighted F1: 0.93\n",
      "Keyword Baseline - Accuracy: 0.77, Weighted F1: 0.67\n",
      "Better Profanity Baseline - Accuracy: 0.77, Weighted F1: 0.68\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "MAX_LENGTH = 150\n",
    "\n",
    "###########################################\n",
    "# DATA LOADING AND PREPROCESSING FUNCTIONS\n",
    "###########################################\n",
    "\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, texts=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        if self.texts is not None:\n",
    "            item['text'] = self.texts[idx]\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    \n",
    "    # Merge annotations and spans on \"annotation\" column\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
    "    \n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [labels + [0]*(max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "                     for labels in labels_list]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    # Split indices for validation (I use validation for the comparison)\n",
    "    indices = list(range(len(texts)))\n",
    "    _, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        selected_texts = [texts[i] for i in indices]\n",
    "        return selected, selected_labels, selected_texts\n",
    "    val_enc, val_labels, val_texts = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist(), texts=val_texts)\n",
    "    return val_dataset, val_texts\n",
    "\n",
    "###########################################\n",
    "# BASELINE METHODS\n",
    "###########################################\n",
    "\n",
    "KEYWORDS = {\"idiot\", \"bitch\", \"moron\", \"fool\", \"stupid\", \"traitor\", \"fuck\", \"gay\", \"hate\", \"fag\", \"faggot\", 'ass', 'fucker', 'retard', 'retarded', 'bad', 'worst', 'weak', 'dweeb'}\n",
    "def keyword_baseline_predict(text, tokenizer, max_length=150):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=False\n",
    "    )\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
    "    pred_labels = []\n",
    "    for token in tokens:\n",
    "        token_clean = token.lstrip(\"Ġ\").lower()\n",
    "        if len(token_clean) < 2:\n",
    "            pred_labels.append(0)\n",
    "        else:\n",
    "            if token_clean in KEYWORDS:\n",
    "                pred_labels.append(1)\n",
    "            else:\n",
    "                pred_labels.append(0)\n",
    "    return pred_labels\n",
    "\n",
    "def better_profanity_baseline_predict(text, tokenizer, max_length=150):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=False\n",
    "    )\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
    "    pred_labels = []\n",
    "    for token in tokens:\n",
    "        token_clean = token.lstrip(\"Ġ\").lower()\n",
    "        if len(token_clean) < 2:\n",
    "            pred_labels.append(0)\n",
    "        else:\n",
    "            if profanity.contains_profanity(token_clean):\n",
    "                pred_labels.append(1)\n",
    "            else:\n",
    "                pred_labels.append(0)\n",
    "    return pred_labels\n",
    "\n",
    "###########################################\n",
    "# MODEL PREDICTION (TRAINED ROBERTA)\n",
    "###########################################\n",
    "\n",
    "def roberta_predict(val_dataset, tokenizer):\n",
    "    model = RobertaForTokenClassification.from_pretrained(\"./final_model\", num_labels=2)\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        per_device_eval_batch_size=8,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        eval_dataset=val_dataset,\n",
    "    )\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    return preds, predictions.label_ids\n",
    "\n",
    "###########################################\n",
    "# EVALUATION & VISUALIZATION\n",
    "###########################################\n",
    "\n",
    "def flatten_predictions(preds):\n",
    "    return np.array(preds).flatten()\n",
    "\n",
    "def evaluate_method(preds_flat, true_flat):\n",
    "    acc = accuracy_score(true_flat, preds_flat)\n",
    "    f1 = f1_score(true_flat, preds_flat, average=\"weighted\")\n",
    "    return acc, f1\n",
    "\n",
    "def compare_models(val_texts, val_dataset, tokenizer):\n",
    "    true_labels = []\n",
    "    for i in range(len(val_dataset)):\n",
    "        true = val_dataset[i]['labels'].cpu().numpy()\n",
    "        true_labels.extend(true)\n",
    "    true_flat = np.array(true_labels)\n",
    "    \n",
    "    # 1. RoBERTa model predictions\n",
    "    roberta_preds, roberta_true = roberta_predict(val_dataset, tokenizer)\n",
    "    roberta_flat = flatten_predictions(roberta_preds)\n",
    "    roberta_acc, roberta_f1 = evaluate_method(roberta_flat, true_flat)\n",
    "    \n",
    "    # 2. Keyword-based baseline predictions\n",
    "    keyword_all = []\n",
    "    for text in val_texts:\n",
    "        keyword_preds = keyword_baseline_predict(text, tokenizer, max_length=150)\n",
    "        keyword_all.extend(keyword_preds)\n",
    "    keyword_flat = np.array(keyword_all)\n",
    "    keyword_acc, keyword_f1 = evaluate_method(keyword_flat, true_flat)\n",
    "    \n",
    "    # 3. Better_profanity baseline predictions\n",
    "    bp_all = []\n",
    "    for text in val_texts:\n",
    "        bp_preds = better_profanity_baseline_predict(text, tokenizer, max_length=150)\n",
    "        bp_all.extend(bp_preds)\n",
    "    bp_flat = np.array(bp_all)\n",
    "    bp_acc, bp_f1 = evaluate_method(bp_flat, true_flat)\n",
    "    \n",
    "    print(\"RoBERTa Model - Accuracy: {:.2f}, Weighted F1: {:.2f}\".format(roberta_acc, roberta_f1))\n",
    "    print(\"Keyword Baseline - Accuracy: {:.2f}, Weighted F1: {:.2f}\".format(keyword_acc, keyword_f1))\n",
    "    print(\"Better Profanity Baseline - Accuracy: {:.2f}, Weighted F1: {:.2f}\".format(bp_acc, bp_f1))\n",
    "    \n",
    "    models = ['RoBERTa', 'Keyword', 'BetterProfanity']\n",
    "    f1_scores = [roberta_f1, keyword_f1, bp_f1]\n",
    "    accuracies = [roberta_acc, keyword_acc, bp_acc]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    ax[0].bar(models, f1_scores, color=['blue', 'orange', 'green'])\n",
    "    ax[0].set_title(\"Weighted F1 Scores\")\n",
    "    ax[0].set_ylim([0, 1])\n",
    "    for i, v in enumerate(f1_scores):\n",
    "        ax[0].text(i, v + 0.02, f\"{v:.2f}\", ha='center', fontweight='bold')\n",
    "    \n",
    "    ax[1].bar(models, accuracies, color=['blue', 'orange', 'green'])\n",
    "    ax[1].set_title(\"Accuracy\")\n",
    "    ax[1].set_ylim([0, 1])\n",
    "    for i, v in enumerate(accuracies):\n",
    "        ax[1].text(i, v + 0.02, f\"{v:.2f}\", ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(\"Comparison of RoBERTa Model vs. Baselines\")\n",
    "    plt.show()\n",
    "\n",
    "###########################################\n",
    "# MAIN\n",
    "###########################################\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    val_dataset, val_texts = prepare_datasets(texts, spans, tokenizer, max_length=150)\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    compare_models(val_texts, val_dataset, tokenizer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Validation Dataset Preparation**  \n",
    "  Merges and tokenizes comments into a 20% hold‑out validation set, aligning tokens with binary toxic/non‑toxic labels via offset mappings as described in Section 2.\n",
    "\n",
    "- **Prediction Pipelines for RoBERTa and Baselines**  \n",
    "  Implements three methods—rule‑based keyword matching (Section 4.1.1), ML‑based better_profanity matching (Section 4.1.2), and the fine‑tuned RoBERTa model (Section 4.2)—to generate token‑level predictions on the same validation data.\n",
    "\n",
    "- **Comparative Evaluation & Visualization**  \n",
    "  Computes token‑level accuracy and weighted F1 for each method, prints the metrics, and displays bar charts comparing performance, directly reflecting the comparative results discussed in Section 5.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics Excluding Padding Tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/2836550041.py:41: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 3220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/2836550041.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (ignoring pad tokens):\n",
      "[[  6440  35414]\n",
      " [     0 111263]]\n",
      "\n",
      "Classification Report (ignoring pad tokens):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.15      0.27     41854\n",
      "           1       0.76      1.00      0.86    111263\n",
      "\n",
      "    accuracy                           0.77    153117\n",
      "   macro avg       0.88      0.58      0.56    153117\n",
      "weighted avg       0.82      0.77      0.70    153117\n",
      "\n",
      "\n",
      "Weighted F1 Score (ignoring pad tokens): 0.6997886886377499\n",
      "Accuracy (ignoring pad tokens): 0.7687128143837719\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "MAX_LENGTH = 150\n",
    "\n",
    "##############################\n",
    "# Data Loading & Preprocessing\n",
    "##############################\n",
    "\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, texts=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        if self.texts is not None:\n",
    "            item['text'] = self.texts[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:  # Skip special tokens\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [labels + [0]*(max_length - len(labels)) if len(labels) < max_length else labels[:max_length] \n",
    "                     for labels in labels_list]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    indices = list(range(len(texts)))\n",
    "    _, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        selected_texts = [texts[i] for i in indices]\n",
    "        return selected, selected_labels, selected_texts\n",
    "    \n",
    "    val_enc, val_labels, val_texts = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist(), texts=val_texts)\n",
    "    return val_dataset, val_texts\n",
    "\n",
    "##############################\n",
    "# Evaluation Ignoring Padding\n",
    "##############################\n",
    "\n",
    "def evaluate_without_padding(true_labels, preds, input_ids, tokenizer):\n",
    "    true_flat = true_labels.flatten()\n",
    "    preds_flat = preds.flatten()\n",
    "    input_ids_flat = input_ids.flatten()\n",
    "    mask = input_ids_flat != tokenizer.pad_token_id\n",
    "    true_filtered = true_flat[mask]\n",
    "    preds_filtered = preds_flat[mask]\n",
    "    \n",
    "    cm = confusion_matrix(true_filtered, preds_filtered)\n",
    "    cr = classification_report(true_filtered, preds_filtered)\n",
    "    f1 = f1_score(true_filtered, preds_filtered, average=\"weighted\")\n",
    "    acc = accuracy_score(true_filtered, preds_filtered)\n",
    "    \n",
    "    return cm, cr, f1, acc\n",
    "\n",
    "##############################\n",
    "# Main Evaluation Code\n",
    "##############################\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    model = RobertaForTokenClassification.from_pretrained(\"./final_model\", num_labels=2)\n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    val_dataset, val_texts = prepare_datasets(texts, spans, tokenizer, max_length=MAX_LENGTH)\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        per_device_eval_batch_size=8,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    preds = np.argmax(predictions.predictions, axis=-1)\n",
    "    true_labels = predictions.label_ids\n",
    "    all_input_ids = []\n",
    "    for i in range(len(val_dataset)):\n",
    "        item = val_dataset[i]\n",
    "        all_input_ids.append(item[\"input_ids\"].numpy())\n",
    "    all_input_ids = np.concatenate(all_input_ids, axis=0)\n",
    "    \n",
    "    # Evaluate metrics ignoring pad tokens\n",
    "    cm, cr, f1, acc = evaluate_without_padding(true_labels, preds, all_input_ids, tokenizer)\n",
    "    \n",
    "    print(\"Confusion Matrix (ignoring pad tokens):\")\n",
    "    print(cm)\n",
    "    print(\"\\nClassification Report (ignoring pad tokens):\")\n",
    "    print(cr)\n",
    "    print(\"\\nWeighted F1 Score (ignoring pad tokens):\", f1)\n",
    "    print(\"Accuracy (ignoring pad tokens):\", acc)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Validation Dataset Preparation & Model Loading**  \n",
    "  Reuses the same data‑loading and tokenization pipeline to build a 20% hold‑out validation set and loads the fine‑tuned RoBERTa model from `./final_model`. This ensures consistency with the experimental setup described in the Data and Methods sections.\n",
    "\n",
    "- **Pad‑Token Masking for Fair Evaluation**  \n",
    "  Gathers `input_ids` for every validation example and constructs a boolean mask to exclude padding tokens (`token_id == pad_token_id`) before computing any metrics. This addresses the concern that pad tokens should not influence accuracy or F1 scores, as emphasized in rigorous evaluation practices.\n",
    "\n",
    "- **Custom Evaluation Function**  \n",
    "  The `evaluate_without_padding` function applies the mask to filter out pad positions, then generates a confusion matrix, classification report, weighted F1, and accuracy on only the real tokens. This aligns with the paper’s focus on precise, token‑level performance analysis (Section 5) by preventing padding artifacts from skewing results.\n",
    "\n",
    "- **End‑to‑End Metric Reporting**  \n",
    "  Calls `Trainer.predict` to obtain raw predictions and labels, applies the pad‑masking evaluation, and prints metrics that reflect true model behavior. This step operationalizes the detailed error analysis and metric transparency advocated in the Results and Discussion sections.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Dataset Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/2257570349.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(data_dir):\n",
    "    comments_df = pd.read_csv(f\"{data_dir}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{data_dir}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{data_dir}/spans.csv\")\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:  # Skip special tokens\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0] * (max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    indices = list(range(len(texts)))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        return selected, selected_labels\n",
    "    \n",
    "    train_enc, train_labels = select_batch(batch_encoding, batch_labels, train_idx)\n",
    "    val_enc, val_labels = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    \n",
    "    train_dataset = ToxicSpanDataset(train_enc, train_labels.tolist())\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist())\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "texts, spans = load_and_preprocess_data(\"data\")\n",
    "train_dataset, val_dataset = prepare_datasets(texts, spans, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`load_and_preprocess_data`**  \n",
    "  Reads `comments.csv`, `annotations.csv`, and `spans.csv`, merges annotations with span indices by the `annotation` key, and constructs two parallel lists: raw comment texts and their associated character‐level toxic span tuples.\n",
    "\n",
    "- **`tokenize_and_align_labels`**  \n",
    "  Uses the tokenizer’s `offset_mapping` to map each token back to character positions, initializes a zeroed label list, and marks tokens as toxic (1) if their span overlaps any toxic span—then removes the offset mapping for compatibility with the training loop.\n",
    "\n",
    "- **`prepare_datasets`**  \n",
    "  Tokenizes and pads all examples to a fixed length, converts label lists into a tensor of the same shape, splits indices into an 80/20 train/validation partition, and returns `ToxicSpanDataset` objects for both sets, ready for model training and evaluation.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class‑Weighted Training with Dynamic Padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4830' max='4830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4830/4830 1:42:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.159896</td>\n",
       "      <td>0.926673</td>\n",
       "      <td>0.929873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.173486</td>\n",
       "      <td>0.926675</td>\n",
       "      <td>0.929875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.164425</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.929615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.167986</td>\n",
       "      <td>0.926679</td>\n",
       "      <td>0.929879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.176657</td>\n",
       "      <td>0.923027</td>\n",
       "      <td>0.926093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.164366</td>\n",
       "      <td>0.926677</td>\n",
       "      <td>0.929877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.195446</td>\n",
       "      <td>0.918462</td>\n",
       "      <td>0.921283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.187410</td>\n",
       "      <td>0.923081</td>\n",
       "      <td>0.926185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.198611</td>\n",
       "      <td>0.919677</td>\n",
       "      <td>0.922525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.16798605024814606, 'eval_accuracy': 0.9266790890269151, 'eval_f1': 0.9298788121032561, 'eval_runtime': 115.1638, 'eval_samples_per_second': 27.96, 'eval_steps_per_second': 3.499, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(labels):\n",
    "    labels_cpu = labels.cpu()\n",
    "    class_counts = np.bincount(labels_cpu.flatten())\n",
    "    total_count = len(labels_cpu.flatten())\n",
    "    class_weights = [total_count / (2 * count) for count in class_counts]\n",
    "    return torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    non_padding_mask = labels != -100\n",
    "    labels = labels[non_padding_mask]\n",
    "    preds = preds[non_padding_mask]\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        labels = labels.to(self.model.device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        class_weights = compute_class_weights(labels).to(self.model.device)\n",
    "        \n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    non_padding_mask = labels != -100\n",
    "    labels = labels[non_padding_mask]\n",
    "    preds = preds[non_padding_mask]\n",
    "    accuracy = (preds == labels).mean().item()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Class‑weighted loss: `compute_class_weights` derives per‑class weights from the label distribution and applies them in `CrossEntropyLoss`, implementing the aggressive weighting strategy from Section 4.2.1.  \n",
    "- Dynamic batching: `DataCollatorWithPadding` enables variable‑length sequences to be batched without manual padding, matching the efficient padding approach described in Methods.  \n",
    "- Padding‑filtered evaluation: `compute_metrics` removes tokens with label –100 (padding) before computing accuracy and F1, ensuring metrics reflect only real tokens as emphasized in the Evaluation section.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class‑Weighted Training with Threshold Adjustment and 70% Prediction Constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8050' max='8050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8050/8050 2:23:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.138100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.158700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.137200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.137900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.140300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.075600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.142100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.126100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.126200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.134400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.113900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.127400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.098800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.085900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.083400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.084900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.079800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.075500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.079700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.077900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.071900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='403' max='403' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [403/403 01:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [483000] at index 0 does not match the shape of the indexed tensor [6440] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[27], line 90\u001b[0m\n",
      "\u001b[1;32m     87\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "\u001b[0;32m---> 90\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation Results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:4136\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n",
      "\u001b[1;32m   4133\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;32m   4135\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n",
      "\u001b[0;32m-> 4136\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   4137\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n",
      "\u001b[1;32m   4140\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n",
      "\u001b[1;32m   4141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   4146\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n",
      "\u001b[1;32m   4147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:4425\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n",
      "\u001b[1;32m   4423\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_losses \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   4424\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_inputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m-> 4425\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   4426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meval_set_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   4427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   4428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   4429\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "\n",
      "Cell \u001b[0;32mIn[27], line 24\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(pred, threshold)\u001b[0m\n",
      "\u001b[1;32m     22\u001b[0m non_padding_mask \u001b[38;5;241m=\u001b[39m labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;32m     23\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels[non_padding_mask]\n",
      "\u001b[0;32m---> 24\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnon_padding_mask\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Apply the 70% rule\u001b[39;00m\n",
      "\u001b[1;32m     27\u001b[0m max_toxic_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.7\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(preds))\n",
      "\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [483000] at index 0 does not match the shape of the indexed tensor [6440] at index 0"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(labels):\n",
    "    labels_cpu = labels.cpu()\n",
    "    class_counts = np.bincount(labels_cpu.flatten())\n",
    "    total_count = len(labels_cpu.flatten())\n",
    "    class_weights = [total_count / (2 * count) for count in class_counts]\n",
    "    return torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "def compute_metrics(pred, threshold=0.7):  # Adjusted threshold here\n",
    "    labels = pred.label_ids.flatten()\n",
    "    logits = pred.predictions\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=-1)\n",
    "    preds = (probs[:, 1] > threshold).int().flatten()\n",
    "    non_padding_mask = labels != -100\n",
    "    labels = labels[non_padding_mask]\n",
    "    \n",
    "    # Ensure preds is a numpy array and apply the mask correctly\n",
    "    preds = np.array(preds)[non_padding_mask]\n",
    "    \n",
    "    # Apply the 70% rule\n",
    "    max_toxic_tokens = int(0.7 * len(preds))\n",
    "    if preds.sum() > max_toxic_tokens:\n",
    "        toxic_indices = np.argsort(probs[:, 1][non_padding_mask])[::-1]\n",
    "        for idx in toxic_indices[max_toxic_tokens:]:\n",
    "            preds[idx] = 0\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        labels = labels.to(self.model.device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        class_weights = compute_class_weights(labels).to(self.model.device)\n",
    "        \n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    bf16=True,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")\n",
    "trainer.save_model('./final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implements class‑weighted loss by computing inverse‑frequency weights from the label distribution and passing them to `CrossEntropyLoss`, reflecting the aggressive weighting strategy outlined in the Methods.  \n",
    "- Defines `compute_metrics` with an adjustable classification threshold and a hard 70% cap on toxic predictions, directly operationalizing the post‑processing constraint described in Section 4.2.2.  \n",
    "- Adjusts hyperparameters (increased epochs, reduced batch size, bf16 precision, disabled intermediate evaluation/saving) to match the experimental variations explored during model tuning.  \n",
    "- Runs the full fine‑tuning loop with `CustomTrainer`, evaluates final performance on non‑padding tokens, and saves the model, aligning with the training and evaluation pipeline reported in the Results.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Rule‑Based Toxic Span Detection Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1236727181.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 3220\n",
      "\n",
      "Evaluating Baseline Rule-Based Approach:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1236727181.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Confusion Matrix:\n",
      "[[371723     14]\n",
      " [110343    920]]\n",
      "\n",
      "Baseline Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87    371737\n",
      "           1       0.99      0.01      0.02    111263\n",
      "\n",
      "    accuracy                           0.77    483000\n",
      "   macro avg       0.88      0.50      0.44    483000\n",
      "weighted avg       0.82      0.77      0.67    483000\n",
      "\n",
      "\n",
      "Baseline Weighted F1 Score: 0.6739407570877253\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "###########################################\n",
    "# DATA LOADING AND PREPROCESSING FUNCTIONS\n",
    "###########################################\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, texts=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        if self.texts is not None:\n",
    "            item['text'] = self.texts[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(\n",
    "        lambda df: list(zip(df[\"start\"], df[\"end\"]))\n",
    "    ).to_dict()\n",
    "    \n",
    "    # Obtain texts and corresponding spans\n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:  # Skip special tokens\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0]*(max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    indices = list(range(len(texts)))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        selected_texts = [texts[i] for i in indices]\n",
    "        return selected, selected_labels, selected_texts\n",
    "    \n",
    "    train_enc, train_labels, train_texts = select_batch(batch_encoding, batch_labels, train_idx)\n",
    "    val_enc, val_labels, val_texts = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    \n",
    "    train_dataset = ToxicSpanDataset(train_enc, train_labels.tolist(), texts=train_texts)\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist(), texts=val_texts)\n",
    "    return train_dataset, val_dataset, val_texts\n",
    "\n",
    "###########################################\n",
    "# BASELINE RULE-BASED APPROACH\n",
    "###########################################\n",
    "\n",
    "TOXIC_KEYWORDS = {\"idiot\", \"bitch\", \"moron\", \"fool\", \"stupid\", \"traitor\", \"donutholes\"}\n",
    "\n",
    "def baseline_predict(text, tokenizer, max_length=150, toxic_keywords=TOXIC_KEYWORDS):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=False\n",
    "    )\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
    "    pred_labels = []\n",
    "    for token in tokens:\n",
    "        token_clean = token.lstrip(\"Ġ\").lower()\n",
    "        if token_clean in toxic_keywords:\n",
    "            pred_labels.append(1)\n",
    "        else:\n",
    "            pred_labels.append(0)\n",
    "    return pred_labels\n",
    "\n",
    "###########################################\n",
    "# EVALUATION FUNCTIONS\n",
    "###########################################\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    accuracy = (preds == labels).mean().item()\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "def evaluate_baseline(val_texts, val_dataset, tokenizer):\n",
    "    all_baseline = []\n",
    "    all_true = []\n",
    "    for i, text in enumerate(val_texts):\n",
    "        baseline_preds = baseline_predict(text, tokenizer, max_length=150)\n",
    "        true_labels = val_dataset[i]['labels'].cpu().numpy().tolist()\n",
    "        all_baseline.extend(baseline_preds)\n",
    "        all_true.extend(true_labels)\n",
    "    \n",
    "    cm = confusion_matrix(all_true, all_baseline)\n",
    "    cr = classification_report(all_true, all_baseline)\n",
    "    f1 = f1_score(all_true, all_baseline, average=\"weighted\")\n",
    "    print(\"Baseline Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nBaseline Classification Report:\")\n",
    "    print(cr)\n",
    "    print(\"\\nBaseline Weighted F1 Score:\", f1)\n",
    "\n",
    "###########################################\n",
    "# MAIN\n",
    "###########################################\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    _, val_dataset, val_texts = prepare_datasets(texts, spans, tokenizer, max_length=150)\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(\"\\nEvaluating Baseline Rule-Based Approach:\")\n",
    "    evaluate_baseline(val_texts, val_dataset, tokenizer)\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `baseline_predict` function applies RoBERTa tokenization and labels each token as toxic if its cleaned form matches any word in the hard‑coded `TOXIC_KEYWORDS` set, otherwise non‑toxic.  \n",
    "- Evaluation loops over the validation split, aggregates token‑level predictions and true labels, then computes a confusion matrix and weighted F1 score to quantify baseline performance.  \n",
    "- These results replicate the rule‑based baseline’s precision–recall trade‑off described in the paper (high precision but near‑zero recall), highlighting the need for deeper contextual modeling.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule‑Based Keyword Matching Baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1236727181.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 3220\n",
      "\n",
      "Evaluating Baseline Rule-Based Approach:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1236727181.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Confusion Matrix:\n",
      "[[371723     14]\n",
      " [110343    920]]\n",
      "\n",
      "Baseline Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87    371737\n",
      "           1       0.99      0.01      0.02    111263\n",
      "\n",
      "    accuracy                           0.77    483000\n",
      "   macro avg       0.88      0.50      0.44    483000\n",
      "weighted avg       0.82      0.77      0.67    483000\n",
      "\n",
      "\n",
      "Baseline Weighted F1 Score: 0.6739407570877253\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "###########################################\n",
    "# DATA LOADING AND PREPROCESSING FUNCTIONS\n",
    "###########################################\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, texts=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        if self.texts is not None:\n",
    "            item['text'] = self.texts[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(\n",
    "        lambda df: list(zip(df[\"start\"], df[\"end\"]))\n",
    "    ).to_dict()\n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:  # Skip special tokens\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0]*(max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    indices = list(range(len(texts)))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        selected_texts = [texts[i] for i in indices]\n",
    "        return selected, selected_labels, selected_texts\n",
    "    \n",
    "    train_enc, train_labels, train_texts = select_batch(batch_encoding, batch_labels, train_idx)\n",
    "    val_enc, val_labels, val_texts = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    \n",
    "    train_dataset = ToxicSpanDataset(train_enc, train_labels.tolist(), texts=train_texts)\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist(), texts=val_texts)\n",
    "    return train_dataset, val_dataset, val_texts\n",
    "\n",
    "###########################################\n",
    "# BASELINE RULE-BASED APPROACH\n",
    "###########################################\n",
    "\n",
    "TOXIC_KEYWORDS = {\"idiot\", \"bitch\", \"moron\", \"fool\", \"stupid\", \"traitor\", \"donutholes\"}\n",
    "\n",
    "def baseline_predict(text, tokenizer, max_length=150, toxic_keywords=TOXIC_KEYWORDS):\n",
    "    # Tokenize text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=False\n",
    "    )\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
    "    pred_labels = []\n",
    "    for token in tokens:\n",
    "        # Cleans the token by stripping the leading Ġ (RoBERTa uses this for whitespace)\n",
    "        token_clean = token.lstrip(\"Ġ\").lower()\n",
    "        # Mark as toxic if token matches one of our keywords; otherwise non-toxic\n",
    "        if token_clean in toxic_keywords:\n",
    "            pred_labels.append(1)\n",
    "        else:\n",
    "            pred_labels.append(0)\n",
    "    return pred_labels\n",
    "\n",
    "###########################################\n",
    "# EVALUATION FUNCTIONS\n",
    "###########################################\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    accuracy = (preds == labels).mean().item()\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "def evaluate_baseline(val_texts, val_dataset, tokenizer):\n",
    "    all_baseline = []\n",
    "    all_true = []\n",
    "    for i, text in enumerate(val_texts):\n",
    "        baseline_preds = baseline_predict(text, tokenizer, max_length=150)\n",
    "        # Gets ground truth labels from the dataset (they are already tokenized)\n",
    "        true_labels = val_dataset[i]['labels'].cpu().numpy().tolist()\n",
    "        all_baseline.extend(baseline_preds)\n",
    "        all_true.extend(true_labels)\n",
    "    cm = confusion_matrix(all_true, all_baseline)\n",
    "    cr = classification_report(all_true, all_baseline)\n",
    "    f1 = f1_score(all_true, all_baseline, average=\"weighted\")\n",
    "    print(\"Baseline Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nBaseline Classification Report:\")\n",
    "    print(cr)\n",
    "    print(\"\\nBaseline Weighted F1 Score:\", f1)\n",
    "\n",
    "###########################################\n",
    "# MAIN\n",
    "###########################################\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    _, val_dataset, val_texts = prepare_datasets(texts, spans, tokenizer, max_length=150)\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    print(\"\\nEvaluating Baseline Rule-Based Approach:\")\n",
    "    evaluate_baseline(val_texts, val_dataset, tokenizer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `baseline_predict` tokenizes each comment and assigns a toxic label (1) to any token whose cleaned form appears in the hard‑coded `TOXIC_KEYWORDS` set, otherwise non‑toxic (0).  \n",
    "- `compute_metrics` takes model outputs (or baseline predictions), flattens them across all tokens, and calculates overall accuracy and weighted F1 to quantify performance.  \n",
    "- `evaluate_baseline` applies `baseline_predict` to every validation example, collects predicted vs. true labels, and prints a confusion matrix, classification report, and weighted F1 score to summarize the rule‑based model’s strengths and weaknesses.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/2257570349.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_data(data_dir):\n",
    "    comments_df = pd.read_csv(f\"{data_dir}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{data_dir}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{data_dir}/spans.csv\")\n",
    "    \n",
    "    # Merge annotations and spans on the \"annotation\" column\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
    "    \n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:  # Skip special tokens\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0] * (max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    indices = list(range(len(texts)))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        return selected, selected_labels\n",
    "    \n",
    "    train_enc, train_labels = select_batch(batch_encoding, batch_labels, train_idx)\n",
    "    val_enc, val_labels = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    \n",
    "    train_dataset = ToxicSpanDataset(train_enc, train_labels.tolist())\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist())\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "texts, spans = load_and_preprocess_data(\"data\")\n",
    "train_dataset, val_dataset = prepare_datasets(texts, spans, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class‑Weighted Token Classification Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4830' max='4830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4830/4830 1:42:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.159896</td>\n",
       "      <td>0.926673</td>\n",
       "      <td>0.929873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.173486</td>\n",
       "      <td>0.926675</td>\n",
       "      <td>0.929875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.164425</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.929615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.167986</td>\n",
       "      <td>0.926679</td>\n",
       "      <td>0.929879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.176657</td>\n",
       "      <td>0.923027</td>\n",
       "      <td>0.926093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.164366</td>\n",
       "      <td>0.926677</td>\n",
       "      <td>0.929877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.195446</td>\n",
       "      <td>0.918462</td>\n",
       "      <td>0.921283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.187410</td>\n",
       "      <td>0.923081</td>\n",
       "      <td>0.926185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.198611</td>\n",
       "      <td>0.919677</td>\n",
       "      <td>0.922525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.16798605024814606, 'eval_accuracy': 0.9266790890269151, 'eval_f1': 0.9298788121032561, 'eval_runtime': 115.1638, 'eval_samples_per_second': 27.96, 'eval_steps_per_second': 3.499, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(labels):\n",
    "    labels_cpu = labels.cpu()\n",
    "    class_counts = np.bincount(labels_cpu.flatten())\n",
    "    total_count = len(labels_cpu.flatten())\n",
    "    class_weights = [total_count / (2 * count) for count in class_counts]\n",
    "    return torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    non_padding_mask = labels != -100\n",
    "    labels = labels[non_padding_mask]\n",
    "    preds = preds[non_padding_mask]\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "\n",
    "# Used DataCollatorWithPadding for dynamic batching\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        labels = labels.to(self.model.device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        class_weights = compute_class_weights(labels).to(self.model.device)\n",
    "        \n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    # Filter out padding tokens\n",
    "    non_padding_mask = labels != -100\n",
    "    labels = labels[non_padding_mask]\n",
    "    preds = preds[non_padding_mask]\n",
    "    accuracy = (preds == labels).mean().item()\n",
    "    return {\"accuracy\": accuracy}\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cross‑entropy loss is overridden to compute per‑batch class weights from the true token labels, ensuring misclassification of the minority (toxic) class is penalized more heavily during fine‑tuning.  \n",
    "- The Hugging Face `Trainer` runs three epochs with batch size 8, 500 warmup steps, weight decay 0.01, step‑wise evaluation every 500 steps, and automatically loads the best checkpoint based on token‑level accuracy.  \n",
    "- Evaluation flattens predictions and labels (masking out padding tokens labeled –100) to compute overall accuracy and weighted F1, reflecting performance only on real tokens.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Trainer with Dynamic Class Weights, Thresholding, and 70% Constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8050' max='8050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8050/8050 2:23:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.138100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.158700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.153200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.137200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.124400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.133800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.137900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.139300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.140300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.101600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.099700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.075600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.142100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.112000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.126100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.126200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.134400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.149700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.113900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.127400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.130100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.098800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.123300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.122200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.100700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.128900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.085900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.101200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.102500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.094100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.096500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.083400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.084900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.079800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.075500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.071500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.079700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.077900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.080900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.071900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='403' max='403' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [403/403 01:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [483000] at index 0 does not match the shape of the indexed tensor [6440] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[27], line 90\u001b[0m\n",
      "\u001b[1;32m     87\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n",
      "\u001b[0;32m---> 90\u001b[0m eval_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation Results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Save the final model\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:4136\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n",
      "\u001b[1;32m   4133\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[1;32m   4135\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n",
      "\u001b[0;32m-> 4136\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   4137\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n",
      "\u001b[1;32m   4140\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n",
      "\u001b[1;32m   4141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[1;32m   4144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   4146\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n",
      "\u001b[1;32m   4147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:4425\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n",
      "\u001b[1;32m   4423\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_losses \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m   4424\u001b[0m     eval_set_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_inputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m-> 4425\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[1;32m   4426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43meval_set_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   4427\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m   4428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;32m   4429\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "\n",
      "Cell \u001b[0;32mIn[27], line 24\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[0;34m(pred, threshold)\u001b[0m\n",
      "\u001b[1;32m     22\u001b[0m non_padding_mask \u001b[38;5;241m=\u001b[39m labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m\n",
      "\u001b[1;32m     23\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels[non_padding_mask]\n",
      "\u001b[0;32m---> 24\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnon_padding_mask\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Apply the 70% rule\u001b[39;00m\n",
      "\u001b[1;32m     27\u001b[0m max_toxic_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.7\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(preds))\n",
      "\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [483000] at index 0 does not match the shape of the indexed tensor [6440] at index 0"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(labels):\n",
    "    labels_cpu = labels.cpu()\n",
    "    class_counts = np.bincount(labels_cpu.flatten())\n",
    "    total_count = len(labels_cpu.flatten())\n",
    "    class_weights = [total_count / (2 * count) for count in class_counts]\n",
    "    return torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "def compute_metrics(pred, threshold=0.7):  # Adjusted threshold here\n",
    "    labels = pred.label_ids.flatten()\n",
    "    logits = pred.predictions\n",
    "    probs = torch.softmax(torch.tensor(logits), dim=-1)\n",
    "    preds = (probs[:, 1] > threshold).int().flatten()\n",
    "    \n",
    "    non_padding_mask = labels != -100\n",
    "    labels = labels[non_padding_mask]\n",
    "    \n",
    "    preds = np.array(preds)[non_padding_mask]\n",
    "    \n",
    "    # Apply the 70% rule\n",
    "    max_toxic_tokens = int(0.7 * len(preds))\n",
    "    if preds.sum() > max_toxic_tokens:\n",
    "        toxic_indices = np.argsort(probs[:, 1][non_padding_mask])[::-1]\n",
    "        for idx in toxic_indices[max_toxic_tokens:]:\n",
    "            preds[idx] = 0\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        labels = labels.to(self.model.device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        class_weights = compute_class_weights(labels).to(self.model.device)\n",
    "        \n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,  # Adjusted learning rate\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    bf16=True,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")\n",
    "\n",
    "trainer.save_model('./final_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The implementation extended `compute_metrics` to apply a 0.7 probability threshold and then enforce a “no more than 70% toxic tokens” rule, but constructed `preds` by indexing `probs[:, 1]` instead of selecting the second class for every token, resulting in a flat array of the wrong length.  \n",
    "- This misaligned prediction array didn’t match the flattened labels mask, so applying the non‑padding mask caused an index‑shape mismatch and the evaluation error.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Class Distribution of Token Labels in the Training Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/3885968139.py:33: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/3885968139.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens - Non-toxic (0): 1483743\n",
      "Training tokens - Toxic (1): 448257\n",
      "Total tokens: 1932000\n",
      "Proportion of toxic tokens: 0.2320170807453416\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "class ToxicSpanDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_train_dataset(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    # Pad the encodings\n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0] * (max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    indices = list(range(len(texts)))\n",
    "    train_idx, _ = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        return selected, selected_labels\n",
    "    train_enc, train_labels = select_batch(batch_encoding, batch_labels, train_idx)\n",
    "    train_dataset = ToxicSpanDataset(train_enc, train_labels.tolist())\n",
    "    return train_dataset\n",
    "\n",
    "def count_token_labels(dataset):\n",
    "    total_zeros = 0\n",
    "    total_ones = 0\n",
    "    for i in range(len(dataset)):\n",
    "        labels = np.array(dataset[i]['labels'])\n",
    "        total_zeros += np.sum(labels == 0)\n",
    "        total_ones += np.sum(labels == 1)\n",
    "    return total_zeros, total_ones\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    train_dataset = prepare_train_dataset(texts, spans, tokenizer, max_length=150)\n",
    "    train_zeros, train_ones = count_token_labels(train_dataset)\n",
    "    total_tokens = train_zeros + train_ones\n",
    "    print(\"Training tokens - Non-toxic (0):\", train_zeros)\n",
    "    print(\"Training tokens - Toxic (1):\", train_ones)\n",
    "    print(\"Total tokens:\", total_tokens)\n",
    "    print(\"Proportion of toxic tokens:\", train_ones / total_tokens)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Computes and prints the total counts and proportion of non‑toxic (0) vs. toxic (1) tokens in the training split, quantifying the class imbalance present in the data.  \n",
    "- Uses this imbalance ratio to inform the later class‑weight computation (so that the loss penalizes toxic‑token errors more heavily), directly supporting the weighted‑loss strategy in the model’s training.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML‑Based Profanity Detection Baseline (using better_profanity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1604921198.py:44: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation samples: 3220\n",
      "\n",
      "Evaluating ML Baseline using better_profanity:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_95869/1604921198.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Baseline Confusion Matrix:\n",
      "[[371649     88]\n",
      " [109807   1456]]\n",
      "\n",
      "ML Baseline Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87    371737\n",
      "           1       0.94      0.01      0.03    111263\n",
      "\n",
      "    accuracy                           0.77    483000\n",
      "   macro avg       0.86      0.51      0.45    483000\n",
      "weighted avg       0.81      0.77      0.68    483000\n",
      "\n",
      "\n",
      "ML Baseline Weighted F1 Score: 0.676455046302137\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"roberta-base\"\n",
    "DATA_DIR = \"data\"\n",
    "\n",
    "###########################################\n",
    "# DATA LOADING AND PREPROCESSING FUNCTIONS\n",
    "###########################################\n",
    "\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, texts=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.texts = texts\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        if self.texts is not None:\n",
    "            item['text'] = self.texts[idx]\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    comments_df = pd.read_csv(f\"{DATA_DIR}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{DATA_DIR}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{DATA_DIR}/spans.csv\")\n",
    "    \n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    \n",
    "    # For each comment, combine spans from all annotations.\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(lambda df: list(zip(df[\"start\"], df[\"end\"]))).to_dict()\n",
    "    \n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    return texts, spans\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=512):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:  # Skip special tokens\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=150):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    for text, span in zip(texts, spans):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0]*(max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    indices = list(range(len(texts)))\n",
    "    _, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        selected_texts = [texts[i] for i in indices]\n",
    "        return selected, selected_labels, selected_texts\n",
    "    \n",
    "    val_enc, val_labels, val_texts = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist(), texts=val_texts)\n",
    "    return val_dataset, val_texts\n",
    "\n",
    "###########################################\n",
    "# ML-BASED BASELINE: BETTER PROFANITY\n",
    "###########################################\n",
    "\n",
    "def ml_baseline_predict(text, tokenizer, max_length=150):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=False\n",
    "    )\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
    "    pred_labels = []\n",
    "    for token in tokens:\n",
    "        token_clean = token.lstrip(\"Ġ\").lower()\n",
    "        if len(token_clean) < 2:\n",
    "            pred_labels.append(0)\n",
    "        else:\n",
    "            # Use better_profanity to check if token is profane\n",
    "            is_profane = profanity.contains_profanity(token_clean)\n",
    "            pred_labels.append(1 if is_profane else 0)\n",
    "    return pred_labels\n",
    "\n",
    "def evaluate_ml_baseline(val_texts, val_dataset, tokenizer):\n",
    "    all_baseline = []\n",
    "    all_true = []\n",
    "    for i, text in enumerate(val_texts):\n",
    "        baseline_preds = ml_baseline_predict(text, tokenizer, max_length=150)\n",
    "        true_labels = val_dataset[i]['labels'].cpu().numpy().tolist()\n",
    "        all_baseline.extend(baseline_preds)\n",
    "        all_true.extend(true_labels)\n",
    "    \n",
    "    cm = confusion_matrix(all_true, all_baseline)\n",
    "    cr = classification_report(all_true, all_baseline)\n",
    "    f1 = f1_score(all_true, all_baseline, average=\"weighted\")\n",
    "    \n",
    "    print(\"ML Baseline Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"\\nML Baseline Classification Report:\")\n",
    "    print(cr)\n",
    "    print(\"\\nML Baseline Weighted F1 Score:\", f1)\n",
    "\n",
    "###########################################\n",
    "# MAIN\n",
    "###########################################\n",
    "\n",
    "def main():\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    texts, spans = load_and_preprocess_data()\n",
    "    val_dataset, val_texts = prepare_datasets(texts, spans, tokenizer, max_length=150)\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    print(\"\\nEvaluating ML Baseline using better_profanity:\")\n",
    "    evaluate_ml_baseline(val_texts, val_dataset, tokenizer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Rule‑Based Baseline (`baseline_predict`)**  \n",
    "  Tokenizes input text, cleans each token (strips leading Ġ and lowercases), and labels it toxic if it exactly matches any word in the predefined `TOXIC_KEYWORDS` set.\n",
    "\n",
    "- **ML‑Based Baseline (`ml_baseline_predict`)**  \n",
    "  Follows the same tokenization and cleaning steps but applies `better_profanity.contains_profanity` to each token to decide toxicity, capturing simple obfuscations and common profanity patterns.\n",
    "\n",
    "- **Evaluation (`evaluate_baseline` & `evaluate_ml_baseline`)**  \n",
    "  Iterates over the validation split, aggregates token‑level predictions and true labels, then computes and prints a confusion matrix, classification report, and weighted F1 score—quantifying each baseline’s precision, recall, and overall effectiveness.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class‑Weighted Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4830' max='4830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4830/4830 1:42:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.159896</td>\n",
       "      <td>0.926673</td>\n",
       "      <td>0.929873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>0.173486</td>\n",
       "      <td>0.926675</td>\n",
       "      <td>0.929875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.164425</td>\n",
       "      <td>0.926398</td>\n",
       "      <td>0.929615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.167986</td>\n",
       "      <td>0.926679</td>\n",
       "      <td>0.929879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>0.176657</td>\n",
       "      <td>0.923027</td>\n",
       "      <td>0.926093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.164366</td>\n",
       "      <td>0.926677</td>\n",
       "      <td>0.929877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.134000</td>\n",
       "      <td>0.195446</td>\n",
       "      <td>0.918462</td>\n",
       "      <td>0.921283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>0.187410</td>\n",
       "      <td>0.923081</td>\n",
       "      <td>0.926185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.132800</td>\n",
       "      <td>0.198611</td>\n",
       "      <td>0.919677</td>\n",
       "      <td>0.922525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'eval_loss': 0.16798605024814606, 'eval_accuracy': 0.9266790890269151, 'eval_f1': 0.9298788121032561, 'eval_runtime': 115.1638, 'eval_samples_per_second': 27.96, 'eval_steps_per_second': 3.499, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "def compute_class_weights(labels):\n",
    "    labels_cpu = labels.cpu()\n",
    "    class_counts = np.bincount(labels_cpu.flatten())\n",
    "    total_count = len(labels_cpu.flatten())\n",
    "    class_weights = [total_count / (2 * count) for count in class_counts]\n",
    "    return torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    \n",
    "    non_padding_mask = labels != -100\n",
    "    labels = labels[non_padding_mask]\n",
    "    preds = preds[non_padding_mask]\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"f1\": f1}\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        labels = labels.to(self.model.device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        class_weights = compute_class_weights(labels).to(self.model.device)\n",
    "        \n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    preds = np.argmax(pred.predictions, axis=-1).flatten()\n",
    "    non_padding_mask = labels != -100\n",
    "    labels = labels[non_padding_mask]\n",
    "    preds = preds[non_padding_mask]\n",
    "    accuracy = (preds == labels).mean().item()\n",
    "    return {\"accuracy\": accuracy}\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Evaluation Results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Class‑Weighted Loss**  \n",
    "  Computes inverse‑frequency weights from the batch’s true token labels and passes them into `CrossEntropyLoss`, so that errors on the minority (toxic) class are penalized more heavily during fine‑tuning.\n",
    "\n",
    "- **Dynamic Batching**  \n",
    "  Uses `DataCollatorWithPadding` to batch variable‑length sequences on the fly, avoiding manual padding logic and ensuring efficient GPU utilization.\n",
    "\n",
    "- **CustomTrainer Integration**  \n",
    "  Overrides `compute_loss` in a subclass of Hugging Face’s `Trainer` to inject the class‑weighted cross‑entropy, while keeping the usual forward pass and logging.\n",
    "\n",
    "- **Training Configuration**  \n",
    "  Runs three epochs with batch size 8, 500 warmup steps, weight decay 0.01, step‑wise evaluation and checkpointing every 500 steps, and automatically loads the best model by token‑level accuracy.\n",
    "\n",
    "- **Padding‑Filtered Evaluation**  \n",
    "  Flattens predictions and labels, excludes tokens where the label is –100 (padding), and computes accuracy (and F1, if using the earlier version) only on real tokens—ensuring padding doesn’t skew reported metrics.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3503848591.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (ignoring pad tokens):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       1.00      0.90      0.95    371737\n",
      "       Toxic       0.76      1.00      0.86    111263\n",
      "\n",
      "    accuracy                           0.93    483000\n",
      "   macro avg       0.88      0.95      0.91    483000\n",
      "weighted avg       0.94      0.93      0.93    483000\n",
      "\n",
      "Weighted F1 Score (ignoring pad tokens): 0.9298788121032561\n",
      "Accuracy (ignoring pad tokens): 0.9266790890269151\n"
     ]
    }
   ],
   "source": [
    "def generate_classification_report(trainer, dataset, tokenizer):\n",
    "    predictions, labels, _ = trainer.predict(dataset)\n",
    "    preds = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    labels_flat = labels.flatten()\n",
    "    preds_flat = preds.flatten()\n",
    "    non_padding_mask = labels_flat != -100\n",
    "    \n",
    "    labels_filtered = labels_flat[non_padding_mask]\n",
    "    preds_filtered = preds_flat[non_padding_mask]\n",
    "    \n",
    "    report = classification_report(labels_filtered, preds_filtered, target_names=['Non-Toxic', 'Toxic'])\n",
    "    accuracy = accuracy_score(labels_filtered, preds_filtered)\n",
    "    weighted_f1 = f1_score(labels_filtered, preds_filtered, average='weighted')\n",
    "    \n",
    "    print(\"Classification Report (ignoring pad tokens):\")\n",
    "    print(report)\n",
    "    print(f\"Weighted F1 Score (ignoring pad tokens): {weighted_f1}\")\n",
    "    print(f\"Accuracy (ignoring pad tokens): {accuracy}\")\n",
    "\n",
    "\n",
    "generate_classification_report(trainer, val_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Overall Performance:**  \n",
    "  - Accuracy: 0.9267  \n",
    "  - Weighted F1: 0.9299  \n",
    "\n",
    "- **Non‑Toxic Class (majority):**  \n",
    "  - Precision 1.00 — almost every token predicted as non‑toxic truly was non‑toxic.  \n",
    "  - Recall 0.90 — the model missed about 10% of non‑toxic tokens (they were falsely labeled toxic).  \n",
    "  - F1 0.95 — strong performance, but slightly hurt by false positives.\n",
    "\n",
    "- **Toxic Class (minority):**  \n",
    "  - Precision 0.76 — roughly one in four toxic predictions was actually non‑toxic (over‑prediction).  \n",
    "  - Recall 1.00 — every true toxic token was correctly identified (no false negatives).  \n",
    "  - F1 0.86 — high recall but lower precision pulls the score down.\n",
    "\n",
    "- **Key Insight:**  \n",
    "  The model achieves perfect recall on toxic spans at the expense of precision, confirming the “over‑prediction” behavior: it labels almost every potential span as toxic, catching all real toxic tokens but also flagging many innocuous ones.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal-Resource CPU-Only Toxic Span Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_q/ts8f31m55sg_0mk57c8_7kd40000gn/T/ipykernel_15339/3286737003.py:36: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  comment_spans = merged.groupby(\"comment_id\").apply(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1600, Validation samples: 400\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 6.18 GB, other allocations: 629.91 MB, max allowed: 6.77 GB). Tried to allocate 147.26 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 328\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;66;03m# Train and test the model with absolute minimal memory settings\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m     model, tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Single epoch\u001b[39;49;00m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Single example per batch\u001b[39;49;00m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Very short sequences\u001b[39;49;00m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# Test examples\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     examples \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are an idiot.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    338\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe weather is nice today.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the worst movie ever, a total disaster.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     ]\n",
      "Cell \u001b[0;32mIn[39], line 227\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_dir, model_name, max_length, output_dir, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m    205\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m    206\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m    207\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39mnum_epochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# Disable reporting to reduce overhead\u001b[39;00m\n\u001b[1;32m    224\u001b[0m )\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# Initialize the Trainer\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mCustomTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_subset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:614\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    613\u001b[0m ):\n\u001b[0;32m--> 614\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/trainer.py:901\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 901\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/modeling_utils.py:3712\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   3708\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3709\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3710\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3711\u001b[0m         )\n\u001b[0;32m-> 3712\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/utils/_device.py:77\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 6.18 GB, other allocations: 629.91 MB, max allowed: 6.77 GB). Tried to allocate 147.26 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "torch.set_default_device('cpu')\n",
    "\n",
    "\n",
    "class ToxicSpanDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(data_dir):\n",
    "    comments_df = pd.read_csv(f\"{data_dir}/comments.csv\")\n",
    "    annotations_df = pd.read_csv(f\"{data_dir}/annotations.csv\")\n",
    "    spans_df = pd.read_csv(f\"{data_dir}/spans.csv\")\n",
    "    \n",
    "    merged = pd.merge(annotations_df, spans_df, on=\"annotation\", how=\"left\")\n",
    "    comment_spans = merged.groupby(\"comment_id\").apply(\n",
    "        lambda df: list(zip(df[\"start\"], df[\"end\"]))\n",
    "    ).to_dict()\n",
    "    \n",
    "    texts = comments_df[\"comment_text\"].tolist()\n",
    "    spans = [comment_spans.get(cid, []) for cid in comments_df[\"comment_id\"]]\n",
    "    \n",
    "    return texts, spans\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(text, spans, tokenizer, max_length=64):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = [0] * len(encoding[\"input_ids\"])\n",
    "    for i, (token_start, token_end) in enumerate(encoding[\"offset_mapping\"]):\n",
    "        if token_start == token_end == 0:\n",
    "            continue\n",
    "        for span_start, span_end in spans:\n",
    "            if not (token_end <= span_start or token_start >= span_end):\n",
    "                labels[i] = 1\n",
    "                break\n",
    "    encoding.pop(\"offset_mapping\")\n",
    "    return encoding, labels\n",
    "\n",
    "def prepare_datasets(texts, spans, tokenizer, max_length=64):\n",
    "    encodings_list = []\n",
    "    labels_list = []\n",
    "    \n",
    "    max_examples = min(2000, len(texts))\n",
    "    for text, span in zip(texts[:max_examples], spans[:max_examples]):\n",
    "        encoding, labels = tokenize_and_align_labels(text, span, tokenizer, max_length)\n",
    "        encodings_list.append(encoding)\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    batch_encoding = tokenizer.pad(encodings_list, padding=\"longest\", max_length=max_length, return_tensors=\"pt\")\n",
    "    padded_labels = [\n",
    "        labels + [0] * (max_length - len(labels)) if len(labels) < max_length else labels[:max_length]\n",
    "        for labels in labels_list\n",
    "    ]\n",
    "    batch_labels = torch.tensor(padded_labels)\n",
    "    \n",
    "    indices = list(range(len(encodings_list)))\n",
    "    train_idx, val_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "    \n",
    "    def select_batch(batch_encoding, batch_labels, indices):\n",
    "        selected = {key: batch_encoding[key][indices] for key in batch_encoding.keys()}\n",
    "        selected_labels = batch_labels[indices]\n",
    "        return selected, selected_labels\n",
    "    \n",
    "    train_enc, train_labels = select_batch(batch_encoding, batch_labels, train_idx)\n",
    "    val_enc, val_labels = select_batch(batch_encoding, batch_labels, val_idx)\n",
    "    \n",
    "    train_dataset = ToxicSpanDataset(train_enc, train_labels.tolist())\n",
    "    val_dataset = ToxicSpanDataset(val_enc, val_labels.tolist())\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def compute_class_weights(labels):\n",
    "    labels_cpu = labels\n",
    "    class_counts = np.bincount(labels_cpu.flatten())\n",
    "\n",
    "    weights = [2.0, 0.5]  # Higher weight for non-toxic class (index 0)\n",
    "    return torch.tensor(weights, dtype=torch.float)\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2, weight=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "        self.bce_loss = torch.nn.CrossEntropyLoss(weight=weight, reduction='none')\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        bce_loss = self.bce_loss(logits, targets)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        probs_t = probs.gather(1, targets.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "\n",
    "        focal_weight = (1 - probs_t) ** self.gamma\n",
    "        \n",
    "        label_weights = torch.ones_like(targets, dtype=torch.float)\n",
    "        label_weights[targets == 0] = self.alpha * 2\n",
    "        \n",
    "        loss = focal_weight * label_weights * bce_loss\n",
    "        return loss.mean()\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids.flatten()\n",
    "    logits = pred.predictions\n",
    "    \n",
    "    non_padding_mask = labels != -100\n",
    "    labels = labels[non_padding_mask]\n",
    "    \n",
    "    if len(logits.shape) == 3:\n",
    "        batch_size, seq_length, num_classes = logits.shape\n",
    "        logits = logits.reshape(-1, num_classes)\n",
    "    \n",
    "    logits_filtered = logits[non_padding_mask]\n",
    "    probs = torch.softmax(torch.tensor(logits_filtered), dim=-1)\n",
    "    preds = (probs[:, 1] > 0.85).int().numpy()  # High threshold\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision = precision_score(labels, preds, average=\"binary\", zero_division=0)\n",
    "    recall = recall_score(labels, preds, average=\"binary\", zero_division=0)\n",
    "    f1 = f1_score(labels, preds, average=\"binary\", zero_division=0)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy, \n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "\n",
    "        class_weights = compute_class_weights(labels)\n",
    "        \n",
    "        focal_loss = FocalLoss(weight=class_weights)\n",
    "        loss = focal_loss(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def train_model(data_dir=\"data\", model_name=\"roberta-base\", max_length=64, output_dir=\"./results\", num_epochs=2, batch_size=1):\n",
    "\n",
    "    tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
    "    model = RobertaForTokenClassification.from_pretrained(model_name, num_labels=2)\n",
    "    \n",
    "    \n",
    "    model = model.cpu()\n",
    "    \n",
    "    \n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    texts, spans = load_and_preprocess_data(data_dir)\n",
    "    train_dataset, val_dataset = prepare_datasets(texts, spans, tokenizer, max_length)\n",
    "    print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    \n",
    "    train_subset = Subset(train_dataset, range(min(20, len(train_dataset))))\n",
    "    eval_subset = Subset(val_dataset, range(min(5, len(val_dataset))))\n",
    "    \n",
    "    \n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=8,\n",
    "        learning_rate=1e-5,\n",
    "        warmup_steps=10,\n",
    "        weight_decay=0.02,\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=20,\n",
    "        save_strategy=\"no\",\n",
    "        load_best_model_at_end=False,\n",
    "        bf16=False,\n",
    "        fp16=False,\n",
    "        dataloader_num_workers=0,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "    \n",
    "    # Initialize the Trainer\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_subset,\n",
    "        eval_dataset=eval_subset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "    # Explicit garbage collection to free memory\n",
    "    gc.collect()\n",
    "    \n",
    "    # Manual evaluation with minimal memory footprint\n",
    "    print(\"Performing manual evaluation...\")\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        \n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        \n",
    "        # Process one example at a time\n",
    "        for i in range(len(eval_subset)):\n",
    "            # Get a single example\n",
    "            example = eval_subset[i]\n",
    "            # Convert to batch format\n",
    "            batch = {k: torch.tensor([v]).cpu() for k, v in example.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            labels = batch.pop(\"labels\")\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # Process the example\n",
    "            for j in range(labels.shape[1]):\n",
    "                if labels[0, j] != -100:  # Not a padding token\n",
    "                    all_labels.append(labels[0, j].item())\n",
    "                    toxic_prob = torch.softmax(logits[0, j], dim=-1)[1].item()\n",
    "                    all_preds.append(1 if toxic_prob > 0.85 else 0)  # High threshold\n",
    "            \n",
    "            # Explicit garbage collection\n",
    "            if i % 10 == 0:\n",
    "                del outputs, logits\n",
    "                gc.collect()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "        recall = recall_score(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "        f1 = f1_score(all_labels, all_preds, average=\"binary\", zero_division=0)\n",
    "        \n",
    "        print(f\"Manual Evaluation Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    trainer.save_model(f\"{output_dir}/final_model\")\n",
    "    print(f\"Model saved to {output_dir}/final_model\")\n",
    "    \n",
    "    return model, tokenizer\n",
    "\n",
    "# Function to test the model on examples\n",
    "def test_example(text, model, tokenizer, threshold=0.85):\n",
    "    model.eval()\n",
    "    \n",
    "    # Process on CPU\n",
    "    encoding = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    toxic_probs = probs[0, :, 1].numpy()\n",
    "    predictions = (toxic_probs > threshold)\n",
    "    \n",
    "    tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "    \n",
    "    print(f\"Text: {text}\")\n",
    "    print(\"Token-level predictions (0: non-toxic, 1: toxic):\")\n",
    "    for i, (token, pred, prob) in enumerate(zip(tokens, predictions, toxic_probs)):\n",
    "        if token in [tokenizer.cls_token, tokenizer.sep_token, tokenizer.pad_token]:\n",
    "            continue\n",
    "        clean_token = token.replace('Ġ', '')\n",
    "        print(f\"  {clean_token}: {'Toxic' if pred else 'Non-toxic'} (Confidence: {prob:.4f})\")\n",
    "    \n",
    "    toxic_count = predictions.sum()\n",
    "    total_tokens = len(predictions) - 2\n",
    "    toxic_percentage = (toxic_count / total_tokens) * 100\n",
    "    \n",
    "    print(f\"\\nSummary: {toxic_count}/{total_tokens} tokens classified as toxic ({toxic_percentage:.1f}%)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = train_model(\n",
    "        data_dir=\"data\", \n",
    "        num_epochs=1,        # Single epoch\n",
    "        batch_size=1,        # Single example per batch\n",
    "        max_length=48        # Very short sequences\n",
    "    )\n",
    "    \n",
    "    # Test examples\n",
    "    examples = [\n",
    "        \"You are an idiot.\",\n",
    "        \"The weather is nice today.\",\n",
    "        \"I can't believe how stupid this is!\",\n",
    "        \"She is smart and has a good heart.\",\n",
    "        \"This is the worst movie ever, a total disaster.\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTesting model on examples:\")\n",
    "    for example in examples:\n",
    "        test_example(example, model, tokenizer, threshold=0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Attempted to train a tiny RoBERTa token‑classification model with extreme memory constraints by:  \n",
    "  - Forcing CPU via `os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"` and `model.cpu()`  \n",
    "  - Drastically reducing sequence length to 48–64 tokens and limiting to a handful of examples (20 train, 5 eval)  \n",
    "  - Disabling mixed precision, using the smallest batch size (1), and subsetting the data  \n",
    "\n",
    "- Despite forcing CPU, Hugging Face’s `Trainer` still detected and moved the model to the MPS device (Apple GPU) by default, leading to an out‑of‑memory error on the MPS backend. The Trainer’s internal `_move_model_to_device` call overrides the earlier CPU setting, so MPS memory was exhausted when loading the model.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Attempted to train a tiny RoBERTa token‑classification model with extreme memory constraints by:  \n",
    "  - Forcing CPU via `os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"` and `model.cpu()`  \n",
    "  - Drastically reducing sequence length to 48–64 tokens and limiting to a handful of examples (20 train, 5 eval)  \n",
    "  - Disabling mixed precision, using the smallest batch size (1), and subsetting the data  \n",
    "\n",
    "- Despite forcing CPU, Hugging Face’s `Trainer` still detected and moved the model to the MPS device (Apple GPU) by default, leading to an out‑of‑memory error on the MPS backend. The Trainer’s internal `_move_model_to_device` call overrides the earlier CPU setting, so MPS memory was exhausted when loading the model.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
